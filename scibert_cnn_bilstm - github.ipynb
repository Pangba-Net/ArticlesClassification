{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6991,
     "status": "ok",
     "timestamp": 1659759405358,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "C9bw4gl-yhai"
   },
   "outputs": [],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1659759405358,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "# from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 4054,
     "status": "ok",
     "timestamp": 1659759564917,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "GzcNQ2OGHy8Z",
    "outputId": "bc02db3c-969a-42cb-8811-f034bcae5541"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-03042941-569f-41ff-9492-0a42e2d2b1b3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UT</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>DISC</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>369459800018</td>\n",
       "      <td>Real-time, nondestructive estimation of crop n...</td>\n",
       "      <td>A2</td>\n",
       "      <td>The optimum vegetation indices (VIs) obtained ...</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383001900005</td>\n",
       "      <td>To promote the stress resilience of sweet pepp...</td>\n",
       "      <td>A2</td>\n",
       "      <td>This study aimed to determine the changes in t...</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>381837100014</td>\n",
       "      <td>Soil degradation has seriously threatened glob...</td>\n",
       "      <td>A2</td>\n",
       "      <td>Therefore, the individual or combined effects ...</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>369517800007</td>\n",
       "      <td>We measured parameters of photosynthetic capac...</td>\n",
       "      <td>A2</td>\n",
       "      <td>We measured parameters of photosynthetic capac...</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382969900003</td>\n",
       "      <td>The transformation of humus substances resulti...</td>\n",
       "      <td>A2</td>\n",
       "      <td>The transformation of humus substances resulti...</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61615</th>\n",
       "      <td>382152500011</td>\n",
       "      <td>We evaluated 160 hip joint radiographs of 40 d...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>The aims were to evaluate the presence of the ...</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61616</th>\n",
       "      <td>366987700001</td>\n",
       "      <td>Background: Enterotoxigenic Escherichia coli (...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>This study aimed to determine the VF and antim...</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61617</th>\n",
       "      <td>375743900005</td>\n",
       "      <td>Large animal veterinary practice is more and m...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>The results of this study suggest that it is i...</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61618</th>\n",
       "      <td>375336400003</td>\n",
       "      <td>Rhodococcus equi is the causative agent of rho...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>equi detection in clinical specimens by the de...</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61619</th>\n",
       "      <td>384016900009</td>\n",
       "      <td>A better understanding of imaging characterist...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>Objectives of this ex vivo, prospective, metho...</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61620 rows × 6 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03042941-569f-41ff-9492-0a42e2d2b1b3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-03042941-569f-41ff-9492-0a42e2d2b1b3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-03042941-569f-41ff-9492-0a42e2d2b1b3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 UT                                           ABSTRACT DISC  \\\n",
       "0      369459800018  Real-time, nondestructive estimation of crop n...   A2   \n",
       "1      383001900005  To promote the stress resilience of sweet pepp...   A2   \n",
       "2      381837100014  Soil degradation has seriously threatened glob...   A2   \n",
       "3      369517800007  We measured parameters of photosynthetic capac...   A2   \n",
       "4      382969900003  The transformation of humus substances resulti...   A2   \n",
       "...             ...                                                ...  ...   \n",
       "61615  382152500011  We evaluated 160 hip joint radiographs of 40 d...   Z6   \n",
       "61616  366987700001  Background: Enterotoxigenic Escherichia coli (...   Z6   \n",
       "61617  375743900005  Large animal veterinary practice is more and m...   Z6   \n",
       "61618  375336400003  Rhodococcus equi is the causative agent of rho...   Z6   \n",
       "61619  384016900009  A better understanding of imaging characterist...   Z6   \n",
       "\n",
       "                                                    text target  label  \n",
       "0      The optimum vegetation indices (VIs) obtained ...      A      9  \n",
       "1      This study aimed to determine the changes in t...      A      9  \n",
       "2      Therefore, the individual or combined effects ...      A      9  \n",
       "3      We measured parameters of photosynthetic capac...      A      9  \n",
       "4      The transformation of humus substances resulti...      A      9  \n",
       "...                                                  ...    ...    ...  \n",
       "61615  The aims were to evaluate the presence of the ...      Z      8  \n",
       "61616  This study aimed to determine the VF and antim...      Z      8  \n",
       "61617  The results of this study suggest that it is i...      Z      8  \n",
       "61618  equi detection in clinical specimens by the de...      Z      8  \n",
       "61619  Objectives of this ex vivo, prospective, metho...      Z      8  \n",
       "\n",
       "[61620 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('drive/MyDrive/bert2/big_class/data3.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1659759566892,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "J0O9vlqnzMz4"
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1659759571560,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "AMbnfqr_zNyg",
    "outputId": "009f45f3-cd0e-49e9-9f59-c7b8065f21e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0212aa6b-da5c-4d72-94a7-ce319c43d349\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UT</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>DISC</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>383137300004</td>\n",
       "      <td>In pot culture, we studied the effects of whea...</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>375210700017</td>\n",
       "      <td>Species richness and turnover rates differed b...</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>373930500026</td>\n",
       "      <td>Leaf nutrient content indicate the nutritional...</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>368299700009</td>\n",
       "      <td>We developed and tested spectroscopic models d...</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>375078700024</td>\n",
       "      <td>Studies have been performed to identify the pr...</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61553</th>\n",
       "      <td>376810700031</td>\n",
       "      <td>To evaluate the prognostic criteria for identi...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61564</th>\n",
       "      <td>374230800006</td>\n",
       "      <td>The SV40 viral oncogene has been used since th...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61569</th>\n",
       "      <td>366437800008</td>\n",
       "      <td>Five calves were inoculated orally at 2 weeks ...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61604</th>\n",
       "      <td>366437200004</td>\n",
       "      <td>Patchy meningeal and parenchymal contrast enha...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61607</th>\n",
       "      <td>366436600009</td>\n",
       "      <td>A 4-year-old, neutered male, British shorthair...</td>\n",
       "      <td>Z6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9563 rows × 6 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0212aa6b-da5c-4d72-94a7-ce319c43d349')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0212aa6b-da5c-4d72-94a7-ce319c43d349 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0212aa6b-da5c-4d72-94a7-ce319c43d349');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 UT                                           ABSTRACT DISC  \\\n",
       "14     383137300004  In pot culture, we studied the effects of whea...   A2   \n",
       "101    375210700017  Species richness and turnover rates differed b...   A2   \n",
       "130    373930500026  Leaf nutrient content indicate the nutritional...   A2   \n",
       "225    368299700009  We developed and tested spectroscopic models d...   A2   \n",
       "248    375078700024  Studies have been performed to identify the pr...   A2   \n",
       "...             ...                                                ...  ...   \n",
       "61553  376810700031  To evaluate the prognostic criteria for identi...   Z6   \n",
       "61564  374230800006  The SV40 viral oncogene has been used since th...   Z6   \n",
       "61569  366437800008  Five calves were inoculated orally at 2 weeks ...   Z6   \n",
       "61604  366437200004  Patchy meningeal and parenchymal contrast enha...   Z6   \n",
       "61607  366436600009  A 4-year-old, neutered male, British shorthair...   Z6   \n",
       "\n",
       "      text target  label  \n",
       "14     NaN      A      9  \n",
       "101    NaN      A      9  \n",
       "130    NaN      A      9  \n",
       "225    NaN      A      9  \n",
       "248    NaN      A      9  \n",
       "...    ...    ...    ...  \n",
       "61553  NaN      Z      8  \n",
       "61564  NaN      Z      8  \n",
       "61569  NaN      Z      8  \n",
       "61604  NaN      Z      8  \n",
       "61607  NaN      Z      8  \n",
       "\n",
       "[9563 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1659759576207,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "gE9fgmEdz9ED"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].fillna(df['ABSTRACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1659759579567,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "wGuqe4yFz-vw",
    "outputId": "ef5f6c77-bef7-4097-d889-f4099fe47f49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-35fa863a-cce3-45cd-b2ed-7148c5b72fad\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UT</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>DISC</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35fa863a-cce3-45cd-b2ed-7148c5b72fad')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-35fa863a-cce3-45cd-b2ed-7148c5b72fad button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-35fa863a-cce3-45cd-b2ed-7148c5b72fad');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UT, ABSTRACT, DISC, text, target, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1659759585750,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "YaoaXsJzzLGi",
    "outputId": "0323d5e6-f35f-44c5-bf69-9307289b0c3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57213    This study explored the contextual relationshi...\n",
       "34935    This will act as a guide for local policy make...\n",
       "48117    The preparation and spectral study of one copp...\n",
       "35348    Harry Truman in this book epitomises 1946 Amer...\n",
       "40899    OBJECTIVE To evaluate the perceived current ne...\n",
       "                               ...                        \n",
       "54343    Findings - Using the novel graph database appr...\n",
       "38158    HGF cells were exposed with NTAPPJ for 1, 2, a...\n",
       "860      To determine the effect of CA on generalist ar...\n",
       "15795    The bearing performance characteristics in ter...\n",
       "56422    The article demonstrates that while some moder...\n",
       "Name: text, Length: 49296, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68397,
     "status": "ok",
     "timestamp": 1659759657171,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "YXHgFP9ws4g4",
    "outputId": "830a7447-d0a0-4597-c989-497718006def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-06 04:19:50--  https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/tensorflow_models/scibert_scivocab_uncased.tar.gz\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.92.194.104\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.92.194.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1216161420 (1.1G) [application/x-tar]\n",
      "Saving to: ‘scibert_scivocab_uncased.tar.gz’\n",
      "\n",
      "scibert_scivocab_un 100%[===================>]   1.13G  21.7MB/s    in 54s     \n",
      "\n",
      "2022-08-06 04:20:45 (21.4 MB/s) - ‘scibert_scivocab_uncased.tar.gz’ saved [1216161420/1216161420]\n",
      "\n",
      "scibert_scivocab_uncased/\n",
      "scibert_scivocab_uncased/bert_model.ckpt.data-00000-of-00001\n",
      "scibert_scivocab_uncased/bert_model.ckpt.index\n",
      "scibert_scivocab_uncased/vocab.txt\n",
      "scibert_scivocab_uncased/bert_model.ckpt.meta\n",
      "scibert_scivocab_uncased/bert_config.json\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/tensorflow_models/scibert_scivocab_uncased.tar.gz\n",
    "!tar -xvf ./scibert_scivocab_uncased.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10789,
     "status": "ok",
     "timestamp": 1659759669840,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "zzPmaTHZv4H-",
    "outputId": "13a62b16-5986-4ef2-fe0c-325b966853a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building PyTorch model from configuration: BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "Converting TensorFlow checkpoint from /content/scibert_scivocab_uncased/bert_model.ckpt\n",
      "Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n",
      "Loading TF weight bert/embeddings/position_embeddings/adam_m with shape [512, 768]\n",
      "Loading TF weight bert/embeddings/position_embeddings/adam_v with shape [512, 768]\n",
      "Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n",
      "Loading TF weight bert/embeddings/token_type_embeddings/adam_m with shape [2, 768]\n",
      "Loading TF weight bert/embeddings/token_type_embeddings/adam_v with shape [2, 768]\n",
      "Loading TF weight bert/embeddings/word_embeddings with shape [31090, 768]\n",
      "Loading TF weight bert/embeddings/word_embeddings/adam_m with shape [31090, 768]\n",
      "Loading TF weight bert/embeddings/word_embeddings/adam_v with shape [31090, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/pooler/dense/bias with shape [768]\n",
      "Loading TF weight bert/pooler/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/pooler/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/pooler/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/pooler/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight cls/predictions/output_bias with shape [31090]\n",
      "Loading TF weight cls/predictions/output_bias/adam_m with shape [31090]\n",
      "Loading TF weight cls/predictions/output_bias/adam_v with shape [31090]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n",
      "Loading TF weight cls/predictions/transform/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight cls/predictions/transform/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight cls/seq_relationship/output_bias with shape [2]\n",
      "Loading TF weight cls/seq_relationship/output_bias/adam_m with shape [2]\n",
      "Loading TF weight cls/seq_relationship/output_bias/adam_v with shape [2]\n",
      "Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n",
      "Loading TF weight cls/seq_relationship/output_weights/adam_m with shape [2, 768]\n",
      "Loading TF weight cls/seq_relationship/output_weights/adam_v with shape [2, 768]\n",
      "Loading TF weight global_step with shape []\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n",
      "Skipping bert/embeddings/LayerNorm/beta/adam_m\n",
      "Skipping bert/embeddings/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n",
      "Skipping bert/embeddings/LayerNorm/gamma/adam_m\n",
      "Skipping bert/embeddings/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n",
      "Skipping bert/embeddings/position_embeddings/adam_m\n",
      "Skipping bert/embeddings/position_embeddings/adam_v\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n",
      "Skipping bert/embeddings/token_type_embeddings/adam_m\n",
      "Skipping bert/embeddings/token_type_embeddings/adam_v\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n",
      "Skipping bert/embeddings/word_embeddings/adam_m\n",
      "Skipping bert/embeddings/word_embeddings/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_0/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_0/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_0/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_0/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_0/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_0/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_0/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_0/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_0/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_0/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_0/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_0/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_0/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_0/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_0/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_0/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_1/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_1/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_1/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_1/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_1/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_1/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_1/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_1/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_1/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_1/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_1/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_1/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_1/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_1/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_1/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_1/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_10/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_10/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_10/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_10/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_10/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_10/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_10/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_10/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_10/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_10/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_10/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_10/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_10/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_10/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_10/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_10/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_11/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_11/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_11/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_11/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_11/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_11/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_11/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_11/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_11/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_11/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_11/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_11/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_11/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_11/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_11/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_11/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_2/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_2/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_2/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_2/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_2/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_2/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_2/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_2/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_2/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_2/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_2/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_2/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_2/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_2/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_2/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_2/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_3/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_3/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_3/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_3/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_3/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_3/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_3/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_3/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_3/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_3/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_3/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_3/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_3/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_3/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_3/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_3/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_4/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_4/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_4/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_4/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_4/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_4/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_4/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_4/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_4/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_4/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_4/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_4/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_4/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_4/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_4/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_4/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_5/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_5/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_5/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_5/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_5/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_5/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_5/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_5/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_5/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_5/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_5/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_5/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_5/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_5/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_5/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_5/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_6/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_6/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_6/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_6/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_6/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_6/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_6/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_6/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_6/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_6/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_6/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_6/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_6/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_6/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_6/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_6/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_7/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_7/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_7/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_7/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_7/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_7/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_7/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_7/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_7/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_7/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_7/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_7/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_7/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_7/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_7/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_7/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_8/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_8/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_8/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_8/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_8/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_8/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_8/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_8/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_8/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_8/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_8/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_8/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_8/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_8/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_8/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_8/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_9/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_9/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_9/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_9/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_9/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_9/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_9/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_9/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_9/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_9/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_9/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_9/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_9/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_9/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_9/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_9/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n",
      "Skipping bert/pooler/dense/bias/adam_m\n",
      "Skipping bert/pooler/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n",
      "Skipping bert/pooler/dense/kernel/adam_m\n",
      "Skipping bert/pooler/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n",
      "Skipping cls/predictions/output_bias/adam_m\n",
      "Skipping cls/predictions/output_bias/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n",
      "Skipping cls/predictions/transform/LayerNorm/beta/adam_m\n",
      "Skipping cls/predictions/transform/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n",
      "Skipping cls/predictions/transform/LayerNorm/gamma/adam_m\n",
      "Skipping cls/predictions/transform/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n",
      "Skipping cls/predictions/transform/dense/bias/adam_m\n",
      "Skipping cls/predictions/transform/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n",
      "Skipping cls/predictions/transform/dense/kernel/adam_m\n",
      "Skipping cls/predictions/transform/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n",
      "Skipping cls/seq_relationship/output_bias/adam_m\n",
      "Skipping cls/seq_relationship/output_bias/adam_v\n",
      "Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n",
      "Skipping cls/seq_relationship/output_weights/adam_m\n",
      "Skipping cls/seq_relationship/output_weights/adam_v\n",
      "Skipping global_step\n",
      "Save PyTorch model to ./scibert_scivocab_uncased/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning\n",
    "!transformers-cli convert --model_type bert \\\n",
    "  --tf_checkpoint './scibert_scivocab_uncased/bert_model.ckpt' \\\n",
    "  --config './scibert_scivocab_uncased/bert_config.json' \\\n",
    "  --pytorch_dump_output './scibert_scivocab_uncased/pytorch_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1659759753695,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "JAzsUN4GwWtT"
   },
   "outputs": [],
   "source": [
    "# from transformers import *\n",
    "\n",
    "bert_model_name = './scibert_scivocab_uncased'\n",
    "\n",
    "config = BertConfig.from_json_file('./scibert_scivocab_uncased/bert_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1659759756655,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "1J1mJcsAwaa2"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12311,
     "status": "ok",
     "timestamp": 1659759768964,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "yFt_HFsct1JA",
    "outputId": "c858581f-c2c1-458d-a56b-78ffaa7cd28f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertModel.from_pretrained(bert_model_name, from_pt=True, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1659759817682,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "X7pkiCvfjJi2"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "def tokenize_sentences(sentences, tokenizer, max_seq_len = 128):\n",
    "    tokenized_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokenized_sentence = tokenizer.encode(\n",
    "                            sentence,                  # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_seq_len,  # Truncate all sentences.\n",
    "                    )\n",
    "        \n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "\n",
    "    return tokenized_sentences\n",
    "\n",
    "def create_attention_masks(tokenized_and_padded_sentences):\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in tokenized_and_padded_sentences:\n",
    "        att_mask = [int(token_id > 0) for token_id in sentence]\n",
    "        attention_masks.append(att_mask)\n",
    "\n",
    "    return np.asarray(attention_masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70834,
     "status": "ok",
     "timestamp": 1659759890904,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "NCtdUhjaGorU",
    "outputId": "b71a1b3c-76e7-4ef9-aba4-ef34400d073c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "train_input_ids = tokenize_sentences(X_train, tokenizer, MAX_LEN)\n",
    "train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "train_attention_masks = create_attention_masks(train_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 16974,
     "status": "ok",
     "timestamp": 1659759909805,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "oD9GQItnHmv2"
   },
   "outputs": [],
   "source": [
    "test_input_ids = tokenize_sentences(X_test, tokenizer, MAX_LEN)\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "test_attention_masks = create_attention_masks(test_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 1333,
     "status": "ok",
     "timestamp": 1659759932126,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "TqRmvfqR03qO"
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics=tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "\n",
    "def build_model(model_layer, learning_rate, dense_dim = 15):\n",
    "    \n",
    "    #define inputs\n",
    "    input_ids = tf.keras.Input(shape=(128,),dtype='int64')\n",
    "    attention_masks = tf.keras.Input(shape=(128,),dtype='int64')\n",
    " \n",
    "    \n",
    "    #insert BERT layer\n",
    "    transformer_layer = model_layer([input_ids,attention_masks])\n",
    "    \n",
    "    #choose only last hidden-state\n",
    "    output = transformer_layer[0]\n",
    "    output = tf.keras.layers.SpatialDropout1D(0.2)(output)\n",
    "    output = tf.keras.layers.Conv1D(64, 3, activation='relu')(output)\n",
    "    output = tf.keras.layers.Bidirectional(LSTM(128))(output)\n",
    "    output = tf.keras.layers.Dense(dense_dim,activation='sigmoid')(output)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
    "\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=learning_rate), loss=loss,metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1931,
     "status": "ok",
     "timestamp": 1650792629294,
     "user": {
      "displayName": "Loser Mystic",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "WsNeMNFactGA",
    "outputId": "5e6a9286-7564-4091-91a9-96fbf127873c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file ./scibert_scivocab_uncased/pytorch_model.bin\n",
      "Loading PyTorch weights from /content/scibert_scivocab_uncased/pytorch_model.bin\n",
      "PyTorch checkpoint contains 134,451,942 parameters\n",
      "Loaded 109,918,464 parameters in the TF 2.0 model.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertModel.from_pretrained(bert_model_name, from_pt=True, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17742,
     "status": "ok",
     "timestamp": 1659759985788,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "kXgVODC6286b",
    "outputId": "b57e7be2-0db1-43b2-992d-64ce3d1f3ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f6b479446e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function wrap at 0x7f6b55c24f80> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109918464   ['input_1[0][0]',                \n",
      "                                thPooling(last_hidd               'input_2[0][0]']                \n",
      "                                en_state=(None, 128                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " spatial_dropout1d (SpatialDrop  (None, 128, 768)    0           ['tf_bert_model[0][0]']          \n",
      " out1D)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 126, 64)      147520      ['spatial_dropout1d[0][0]']      \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 256)          197632      ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 15)           3855        ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,267,471\n",
      "Trainable params: 110,267,471\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "SciBERT= build_model(model, learning_rate = 1e-5)\n",
    "SciBERT.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKutUHJ35e8E"
   },
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1659759985788,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "ASXGCMQG5uJ1"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [tf.keras.callbacks.ModelCheckpoint('scibert3.h5', monitor='val_accuracy', save_best_only = True, save_weights_only = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1968340,
     "status": "ok",
     "timestamp": 1659761967115,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "keMgwpL97oN8",
    "outputId": "5ec55fce-61b0-43b9-a127-e0b7f589e260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156/1156 [==============================] - ETA: 0s - loss: 0.9867 - accuracy: 0.7306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1156/1156 [==============================] - 676s 562ms/step - loss: 0.9867 - accuracy: 0.7306 - val_loss: 0.6766 - val_accuracy: 0.7951\n",
      "Epoch 2/3\n",
      "1156/1156 [==============================] - 645s 558ms/step - loss: 0.5673 - accuracy: 0.8306 - val_loss: 0.6079 - val_accuracy: 0.8137\n",
      "Epoch 3/3\n",
      "1156/1156 [==============================] - 645s 558ms/step - loss: 0.4388 - accuracy: 0.8685 - val_loss: 0.5928 - val_accuracy: 0.8181\n"
     ]
    }
   ],
   "source": [
    "history = SciBERT.fit((train_input_ids, train_attention_masks),y_train,batch_size =32,                  \n",
    "                epochs=3,\n",
    "                validation_split = 0.25,\n",
    "                callbacks=callbacks_list\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1659761968130,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "LMpN1AZk33OS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70291,
     "status": "ok",
     "timestamp": 1659762038413,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "2UyKJp2kwmxa",
    "outputId": "f5b6fd58-5ead-45b4-bb21-f96533b9716e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "predictions = SciBERT.predict([test_input_ids,test_attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1659762038414,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "DwPhPrMgy4ca"
   },
   "outputs": [],
   "source": [
    "# y_test = df_test.label.values\n",
    "y_pred = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1659762038414,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "g4HoQSMi4NBw",
    "outputId": "3a3f766d-bc2d-40e3-877e-7c92f997ac27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       836\n",
      "           1       0.93      0.86      0.90       779\n",
      "           2       0.78      0.83      0.81       847\n",
      "           3       0.85      0.86      0.86       843\n",
      "           4       0.91      0.86      0.88       853\n",
      "           5       0.71      0.62      0.66       805\n",
      "           6       0.85      0.90      0.87       823\n",
      "           7       0.79      0.90      0.84       823\n",
      "           8       0.80      0.80      0.80       823\n",
      "           9       0.79      0.80      0.80       824\n",
      "          10       0.86      0.91      0.89       815\n",
      "          11       0.81      0.77      0.79       832\n",
      "          12       0.72      0.70      0.71       833\n",
      "          13       0.78      0.69      0.73       798\n",
      "          14       0.91      0.92      0.91       790\n",
      "\n",
      "    accuracy                           0.82     12324\n",
      "   macro avg       0.82      0.82      0.81     12324\n",
      "weighted avg       0.82      0.82      0.81     12324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1659762759214,
     "user": {
      "displayName": "Fly",
      "userId": "17767889626547743162"
     },
     "user_tz": -480
    },
    "id": "FM61TTig4Jio"
   },
   "outputs": [],
   "source": [
    "bert_report = pd.DataFrame(classification_report(y_test, y_pred,output_dict=True)).T\n",
    "bert_report.to_csv('drive/MyDrive/bert2/big_class/report_scibert2.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "scibert_cnn_bilstm.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
